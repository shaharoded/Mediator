# Mediator â€” Knowledge-Based Temporal Abstraction

<p align="center">
  <img src="images/mediator_architecture.png" alt="Mediator Architecture" width="800"/>
</p>

## Overview

The **Mediator** is a Python-based implementation of Knowledge-Based Temporal Abstraction (KBTA) that converts time-stamped clinical data into interval-based symbolic abstractions for research and predictive modeling.

**Key Features:**
- âœ… **Hierarchical abstractions** â€” Raw Concepts â†’ Events â†’ States â†’ Trends â†’ Contexts â†’ Patterns
- âœ… **XSD schema validation** â€” Structural validation for all TAK definitions
- âœ… **Production-ready** â€” SQLite backend, async processing, comprehensive tests
- âœ… **Extensible** â€” XML-based TAK definitions (no code changes needed)

**Theoretical Foundation:**

This implementation is based on the KBTA framework:

1. **Shahar, Y., & Musen, M. A. (1996).** "Knowledge-based temporal abstraction in clinical domains." *Artificial Intelligence in Medicine*, 8(3), 267-298.
   - DOI: [10.1016/0933-3657(95)00036-4](https://doi.org/10.1016/0933-3657(95)00036-4)

2. **Shalom, E., Goldstein, A., Weiss, R., Selivanova, M., Cohen, N. M., & Shahar, Y. (2024).** "Implementation and evaluation of a system for assessment of the quality of long-term management of patients at a geriatric hospital." *Journal of Biomedical Informatics*, 156, 104686.
   - DOI: [10.1016/j.jbi.2024.104686](https://doi.org/10.1016/j.jbi.2024.104686)

---

## Repository Structure

```
Mediator/
â”œâ”€â”€ backend/                                # Database layer
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ generate_synthetic_data.ipynb   # Synthetic data generator
â”‚   â”‚   â”œâ”€â”€ mediator.db                     # SQLite database (auto-created)
â”‚   â”‚   â””â”€â”€ synthetic_input_data.csv        # Example input CSV
â”‚   â”œâ”€â”€ queries/                            # SQL templates (DDL, DML, SELECT)
â”‚   â”œâ”€â”€ config.py                           # Database paths
â”‚   â””â”€â”€ dataaccess.py                       # Database access + CLI
â”œâ”€â”€ core/                                   # TAK engine
â”‚   â”œâ”€â”€ knowledge-base/                     # TAK definitions (XML)
â”‚   â”‚   â”œâ”€â”€ raw-concepts/                   # Single/multi-attribute concepts
â”‚   â”‚   â”œâ”€â”€ events/                         # Point-in-time events
â”‚   â”‚   â”œâ”€â”€ states/                         # Interval-based states
â”‚   â”‚   â”œâ”€â”€ trends/                         # Slope-based trends
â”‚   â”‚   â”œâ”€â”€ contexts/                       # Background contexts
â”‚   â”‚   â”œâ”€â”€ patterns/                       # Temporal patterns (TODO)
â”‚   â”‚   â”œâ”€â”€ global_clippers.json            # Global START/END clippers
â”‚   â”‚   â”œâ”€â”€ tak_schema.xsd                  # XSD validation schema
â”‚   â”‚   â””â”€â”€ TAK_README.json                 # TAK documentation + instructions
â”‚   â”œâ”€â”€ tak/                                # TAK implementation
â”‚   â”‚   â”œâ”€â”€ tak.py                          # Base classes + repository
â”‚   â”‚   â”œâ”€â”€ raw_concept.py                  # RawConcept TAK
â”‚   â”‚   â”œâ”€â”€ event.py                        # Event TAK
â”‚   â”‚   â”œâ”€â”€ state.py                        # State TAK
â”‚   â”‚   â”œâ”€â”€ trend.py                        # Trend TAK
â”‚   â”‚   â”œâ”€â”€ context.py                      # Context TAK
â”‚   â”‚   â”œâ”€â”€ pattern.py                      # Pattern TAK (TODO)
â”‚   â”‚   â””â”€â”€ utils.py                        # Shared utilities
â”‚   â”œâ”€â”€ config.py                           # TAK paths
â”‚   â””â”€â”€ mediator.py                         # Orchestration engine + CLI
â”œâ”€â”€ images/                                 # Documentation assets
â”œâ”€â”€ unittests/                              # Comprehensive test suite
â”œâ”€â”€ README.md                               # This file
â””â”€â”€ requirements.txt                        # Python dependencies
```

---

## Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/Mediator.git
cd Mediator

# Install dependencies
pip install -r requirements.txt
```

### 2. Setup Database

```bash
# Create database tables
python -m backend.dataaccess --create_db

# Load example data
python -m backend.dataaccess --load_csv backend/data/synthetic_input_data.csv
```

### 3. Run Pipeline

```bash
# Process all patients
python -m core.mediator

# Process specific patients
python -m core.mediator --patients 1000,1001,1002

# Debug mode
python -m core.mediator --log-level DEBUG --patients 1000
```

---

## Database Schema

### CSV Input Requirements

**Required columns:**
- `PatientId` â€” Integer patient identifier
- `ConceptName` â€” Concept/measurement name (matches TAK names)
- `StartDateTime` â€” Timestamp (YYYY-MM-DD HH:MM:SS)
- `EndDateTime` â€” Timestamp
- `Value` â€” Measurement value (numeric or string)

**Optional columns:**
- `Unit` â€” Measurement unit

**Example CSV:**
```csv
PatientId,ConceptName,StartDateTime,EndDateTime,Value,Unit
1000,GLUCOSE_LAB_MEASURE,2024-01-01 08:00:00,2024-01-01 08:00:00,120,mg/dL
1000,BASAL_DOSAGE,2024-01-01 21:00:00,2024-01-01 21:00:00,15,U
1000,BASAL_ROUTE,2024-01-01 21:00:00,2024-01-01 21:00:00,SubCutaneous,
```

---

## CLI Reference

### Database Operations

```bash
# Create/recreate database
python -m backend.dataaccess --create_db [--drop]

# Load CSV
python -m backend.dataaccess --load_csv data/input.csv

# Replace existing data
python -m backend.dataaccess --load_csv data/input.csv \
    --replace-input --clear-output-qa --yes
```

**Features:**
- âœ… Auto-detects large files and uses Dask if available (â‰¥100 MB)
- âœ… Transactional loading (all-or-nothing validation)
- âœ… Interactive prompts (overridable with `--yes`)

---

### Core (Mediator Pipeline)

```bash
# Process all patients
python -m core.mediator

# Process subset
python -m core.mediator --patients 1000,1001

# Custom concurrency
python -m core.mediator --max-concurrent 8

# Custom KB and DB paths
python -m core.mediator --kb core/knowledge-base --db data/mediator.db

# Debug logging
python -m core.mediator --log-level DEBUG --patients 101,102,103
```

**Workflow:**
1. **Build TAK repository** â€” Load and validate all TAK definitions from `knowledge-base/`
2. **Process patients** â€” For each patient:
   - Extract input data from `InputPatientData`
   - Apply TAKs in dependency order (Raw Concepts â†’ Events â†’ States â†’ Trends â†’ Contexts)
   - Write abstractions to `OutputPatientData`
3. **Report stats** â€” Print timing and output row counts per patient

---

## Programmatic Usage

### Database Access

```python
from backend.dataaccess import DataAccess

da = DataAccess()

# Create tables
da.create_db(drop=False)
da.load_csv_to_input("data/input.csv", if_exists='append')

# Query
rows = da.fetch_records(
    "SELECT * FROM InputPatientData WHERE PatientId = ?",
    (1000,)
)
```

### TAK Processing

```python
from pathlib import Path
from core.mediator import Mediator

mediator = Mediator(Path("core/knowledge-base"))
repo = mediator.build_repository()

# Process patients
stats = mediator.run(max_concurrent=4, patient_subset=[1000, 1001])
print(stats)
```

---

## TAK Documentation

For detailed information about TAK families, XML schema, validation rules, and examples:

ðŸ“– **See:** [`core/knowledge-base/TAK_README.md`](core/knowledge-base/TAK_README.md)

**Quick TAK Reference:**
- **Raw Concepts** â€” Bridge InputPatientData â†’ pipeline (multi-attr tuples, numeric ranges, nominal values)
- **Events** â€” Point-in-time occurrences (multi-source, flexible constraints)
- **States** â€” Interval-based symbolic states (discretization + merging)
- **Trends** â€” Slope-based trends (Increasing/Decreasing/Steady)
- **Contexts** â€” Background facts (windowing + clipping)

---

## Testing

```bash
# Run all tests
python -m pytest unittests/ -v

# Run specific test modules
python -m pytest unittests/test_raw_concept.py -v
python -m pytest unittests/test_event.py -v
python -m pytest unittests/test_state.py -v
python -m pytest unittests/test_trend.py -v
python -m pytest unittests/test_context.py -v
python -m pytest unittests/test_mediator.py -v
```

**Coverage:** 53 tests covering all TAK families + end-to-end pipeline.

---

## Common Issues

### Database Not Found
**Error:** `Database file 'mediator.db' does not exist`

**Fix:**
```bash
python -m backend.dataaccess --create_db
```

### CSV Validation Failure
**Error:** `Missing required columns: PatientId`

**Fix:** Rename CSV headers to match canonical names (`PatientId`, `ConceptName`, etc.)

### TAK Validation Error
**Error:** `Element 'tuple-order': This element is not expected`

**Fix:** Check XML element order matches schema (see [`TAK_README.md`](core/knowledge-base/TAK_README.md#critical-element-order-rules))

---

## Citation

```bibtex
@article{shahar1996knowledge,
  title={Knowledge-based temporal abstraction in clinical domains},
  author={Shahar, Yuval and Musen, Mark A},
  journal={Artificial Intelligence in Medicine},
  volume={8},
  number={3},
  pages={267--298},
  year={1996},
  publisher={Elsevier}
}

@article{shalom2024implementation,
  title={Implementation and evaluation of a system for assessment of the quality of long-term management of patients at a geriatric hospital},
  author={Shalom, Erez and Goldstein, Avraham and Weiss, Robert and Selivanova, Marina and Cohen, Nir Menachemi and Shahar, Yuval},
  journal={Journal of Biomedical Informatics},
  volume={156},
  pages={104686},
  year={2024},
  publisher={Elsevier}
}
```
---

**Maintained by:** Shahar Oded